{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "n3vTp1VW8fKa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_B6wPG3g8fKi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6TbBs0Pp8fKj"
   },
   "outputs": [],
   "source": [
    "path = 'moby_dick.txt'\n",
    "text = open(path, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1OFsbUF8fKk",
    "outputId": "e72290bb-1a63-4f11-975c-787751201064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1\n",
      "\n",
      "Loomings.\n",
      "\n",
      "\n",
      "Call me Ishmael.  Some years ago--never mind how long\n",
      "precisely--having little or no money in my purse, and nothing\n",
      "particular to interest me on shore, I thought I would sail about a\n",
      "little and see the watery part of the world.  It is a way I have of\n",
      "driving off the spleen and regulating the circulation.  Whenever I\n",
      "find myself growing grim about the mouth; whenever it is a damp,\n",
      "drizzly November in my soul; whenever I find myself involuntarily\n",
      "pausing before coffin warehouses, and bringing up the rear of every\n",
      "funeral I meet; and especially whenever my hypos get such an\n"
     ]
    }
   ],
   "source": [
    "print(text[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tibYcjIe8fKm",
    "outputId": "53661bf6-b9b4-49cd-aab7-cec9ff7096b4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Unique characters in the file \n",
    "vocab = sorted(set(text))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TjIpM7Xk8fKn"
   },
   "outputs": [],
   "source": [
    "#text Processing\n",
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sMxJ4KEP8fKo"
   },
   "outputs": [],
   "source": [
    "#char_to_ind\n",
    "#char_to_ind['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aJRJGENr8fKo"
   },
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "w_udxx6e8fKp"
   },
   "outputs": [],
   "source": [
    "#int_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlpMmM128fKs",
    "outputId": "4a5b7b6a-4a67-4c12-8fd7-d6662976685d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 33, 26, ..., 12,  0,  0])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = np.array([char_to_ind[c]for c in text])\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78Uy9ZF58fKt",
    "outputId": "af0d3da6-556e-40b8-abe0-d836943d2b3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198622,)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7ZSQ_8e8fKv",
    "outputId": "3880047f-5a89-4a9c-bb8c-d1bf6ca1718a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1\n",
      "\n",
      "Loomings.\n",
      "\n",
      "\n",
      "Call me Ishmael.  Some years ago--never mind how long\n",
      "precisely--having little or no money in my purse, and nothing\n",
      "particular to interest me on shore, I thought I would sail ab\n"
     ]
    }
   ],
   "source": [
    "#Let's see the difirence\n",
    "# real text\n",
    "sample = text[:200]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iK3zt_jT8fKw",
    "outputId": "bca51ea8-76a3-48fb-92ea-5cc21564c379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 33, 26, 41, 45, 30, 43,  1, 14,  0,  0, 37, 69, 69, 67, 63, 68,\n",
       "       61, 73, 12,  0,  0,  0, 28, 55, 66, 66,  1, 67, 59,  1, 34, 73, 62,\n",
       "       67, 55, 59, 66, 12,  1,  1, 44, 69, 67, 59,  1, 79, 59, 55, 72, 73,\n",
       "        1, 55, 61, 69, 11, 11, 68, 59, 76, 59, 72,  1, 67, 63, 68, 58,  1,\n",
       "       62, 69, 77,  1, 66, 69, 68, 61,  0, 70, 72, 59, 57, 63, 73, 59, 66,\n",
       "       79, 11, 11, 62, 55, 76, 63, 68, 61,  1, 66, 63, 74, 74, 66, 59,  1,\n",
       "       69, 72,  1, 68, 69,  1, 67, 69, 68, 59, 79,  1, 63, 68,  1, 67, 79,\n",
       "        1, 70, 75, 72, 73, 59, 10,  1, 55, 68, 58,  1, 68, 69, 74, 62, 63,\n",
       "       68, 61,  0, 70, 55, 72, 74, 63, 57, 75, 66, 55, 72,  1, 74, 69,  1,\n",
       "       63, 68, 74, 59, 72, 59, 73, 74,  1, 67, 59,  1, 69, 68,  1, 73, 62,\n",
       "       69, 72, 59, 10,  1, 34,  1, 74, 62, 69, 75, 61, 62, 74,  1, 34,  1,\n",
       "       77, 69, 75, 66, 58,  1, 73, 55, 63, 66,  1, 55, 56])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoded text\n",
    "encoded_text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "uB0ST-zv8fKw"
   },
   "outputs": [],
   "source": [
    "seq_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IV1PKnyV8fKw",
    "outputId": "147e5cce-841e-4c7a-9c8b-f1908ec1d370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9905"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq = len(text)//(seq_len+1)\n",
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ADh7rcm8fKx",
    "outputId": "1dd9a240-5ff4-4626-ece8-5535b39aaa6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "H\n",
      "A\n",
      "P\n",
      "T\n",
      "E\n",
      "R\n",
      " \n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "L\n",
      "o\n",
      "o\n",
      "m\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "m\n",
      "e\n",
      " \n",
      "I\n",
      "s\n",
      "h\n",
      "m\n",
      "a\n",
      "e\n",
      "l\n",
      ".\n",
      " \n",
      " \n",
      "S\n",
      "o\n",
      "m\n",
      "e\n",
      " \n",
      "y\n",
      "e\n",
      "a\n",
      "r\n",
      "s\n",
      " \n",
      "a\n",
      "g\n",
      "o\n",
      "-\n",
      "-\n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "d\n",
      " \n",
      "h\n",
      "o\n",
      "w\n",
      " \n",
      "l\n",
      "o\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "c\n",
      "i\n",
      "s\n",
      "e\n",
      "l\n",
      "y\n",
      "-\n",
      "-\n",
      "h\n",
      "a\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "l\n",
      "i\n",
      "t\n",
      "t\n",
      "l\n",
      "e\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "n\n",
      "o\n",
      " \n",
      "m\n",
      "o\n",
      "n\n",
      "e\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "y\n",
      " \n",
      "p\n",
      "u\n",
      "r\n",
      "s\n",
      "e\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "a\n",
      "r\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "m\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "r\n",
      "e\n",
      ",\n",
      " \n",
      "I\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "I\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "s\n",
      "a\n",
      "i\n",
      "l\n",
      " \n",
      "a\n",
      "b\n",
      "o\n",
      "u\n",
      "t\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "l\n",
      "i\n",
      "t\n",
      "t\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "e\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      ".\n",
      " \n",
      " \n",
      "I\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "w\n",
      "a\n",
      "y\n",
      " \n",
      "I\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "d\n",
      "r\n",
      "i\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "o\n",
      "f\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "p\n",
      "l\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "u\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "i\n",
      "r\n",
      "c\n",
      "u\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ".\n",
      " \n",
      " \n",
      "W\n",
      "h\n",
      "e\n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "I\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "n\n",
      "d\n",
      " \n",
      "m\n",
      "y\n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "g\n",
      "r\n",
      "o\n",
      "w\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "r\n",
      "i\n",
      "m\n",
      " \n",
      "a\n",
      "b\n",
      "o\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "u\n",
      "t\n",
      "h\n",
      ";\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "d\n",
      "a\n",
      "m\n",
      "p\n",
      ",\n",
      "\n",
      "\n",
      "d\n",
      "r\n",
      "i\n",
      "z\n",
      "z\n",
      "l\n",
      "y\n",
      " \n",
      "N\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "y\n",
      " \n",
      "s\n",
      "o\n",
      "u\n",
      "l\n",
      ";\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "I\n",
      " \n",
      "f\n",
      "i\n",
      "n\n",
      "d\n",
      " \n",
      "m\n",
      "y\n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "v\n",
      "o\n",
      "l\n",
      "u\n",
      "n\n",
      "t\n",
      "a\n",
      "r\n",
      "i\n",
      "l\n",
      "y\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "b\n",
      "e\n",
      "f\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "f\n",
      "f\n",
      "i\n",
      "n\n",
      " \n",
      "w\n",
      "a\n",
      "r\n",
      "e\n",
      "h\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# Create Training Sequences\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "for i in char_dataset.take(500):\n",
    "     print(ind_to_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vuiuNPRo8fKx"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zhtvzCE38fKx"
   },
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1] # melih can ore\n",
    "    target_txt = seq[1:] # elih can orel\n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bo_6kspk8fKx",
    "outputId": "155b8059-f7cc-4aed-df0b-818bd898fd2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28 33 26 41 45 30 43  1 14  0  0 37 69 69 67 63 68 61 73 12  0  0  0 28\n",
      " 55 66 66  1 67 59  1 34 73 62 67 55 59 66 12  1  1 44 69 67 59  1 79 59\n",
      " 55 72 73  1 55 61 69 11 11 68 59 76 59 72  1 67 63 68 58  1 62 69 77  1\n",
      " 66 69 68 61  0 70 72 59 57 63 73 59 66 79 11 11 62 55 76 63 68 61  1 66\n",
      " 63 74 74 66 59  1 69 72  1 68 69  1 67 69 68 59 79  1 63 68  1 67 79  1]\n",
      "CHAPTER 1\n",
      "\n",
      "Loomings.\n",
      "\n",
      "\n",
      "Call me Ishmael.  Some years ago--never mind how long\n",
      "precisely--having little or no money in my \n",
      "\n",
      "\n",
      "[33 26 41 45 30 43  1 14  0  0 37 69 69 67 63 68 61 73 12  0  0  0 28 55\n",
      " 66 66  1 67 59  1 34 73 62 67 55 59 66 12  1  1 44 69 67 59  1 79 59 55\n",
      " 72 73  1 55 61 69 11 11 68 59 76 59 72  1 67 63 68 58  1 62 69 77  1 66\n",
      " 69 68 61  0 70 72 59 57 63 73 59 66 79 11 11 62 55 76 63 68 61  1 66 63\n",
      " 74 74 66 59  1 69 72  1 68 69  1 67 69 68 59 79  1 63 68  1 67 79  1 70]\n",
      "HAPTER 1\n",
      "\n",
      "Loomings.\n",
      "\n",
      "\n",
      "Call me Ishmael.  Some years ago--never mind how long\n",
      "precisely--having little or no money in my p\n"
     ]
    }
   ],
   "source": [
    "dataset = sequences.map(create_seq_targets)\n",
    "\n",
    "for input_txt, target_txt in  dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    # There is an extra whitespace!\n",
    "    print(''.join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfGzVIhH8fKx",
    "outputId": "9baf2932-a9ec-4ce5-d237-abd6fe4253c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IU6q3L88fKy"
   },
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "M2njqhyK8fKy"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embed_dim = 64\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_neurons = 512\n",
    "rnn_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OW3ClzQ-8fKz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "cQ-DV6pK8fKz"
   },
   "outputs": [],
   "source": [
    "#Loss\n",
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "WGhnP6jI8fKz"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons,rnn_hidden,batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
    "    \n",
    "    # RNN Layer\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    \n",
    "    # Hidden Layer\n",
    "    model.add(GRU(rnn_hidden,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    \n",
    "    # Final Dense Layer \n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "KO4PCgtW8fK0"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size=vocab_size,\n",
    "                    embed_dim=embed_dim,\n",
    "                    rnn_hidden=rnn_hidden,\n",
    "                    rnn_neurons=rnn_neurons,\n",
    "                    batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XWdCfVH-8fK0",
    "outputId": "fd81e0ba-32f3-4f31-e394-174f1c4e077c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5184      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 512)          887808    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (128, None, 256)          591360    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 81)           20817     \n",
      "=================================================================\n",
      "Total params: 1,505,169\n",
      "Trainable params: 1,505,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4mfWXDF8fK1"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "e0CZHoS28fK1"
   },
   "outputs": [],
   "source": [
    "epochs = 30 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhneMy6N8fK1",
    "outputId": "49d41130-09cf-4c1b-9207-a9fed3a5ae65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "77/77 [==============================] - 209s 3s/step - loss: 3.5374\n",
      "Epoch 2/30\n",
      "77/77 [==============================] - 215s 3s/step - loss: 2.7440\n",
      "Epoch 3/30\n",
      "77/77 [==============================] - 212s 3s/step - loss: 2.3035\n",
      "Epoch 4/30\n",
      "77/77 [==============================] - 211s 3s/step - loss: 2.0788\n",
      "Epoch 5/30\n",
      "77/77 [==============================] - 210s 3s/step - loss: 1.9305\n",
      "Epoch 6/30\n",
      "77/77 [==============================] - 213s 3s/step - loss: 1.8215\n",
      "Epoch 7/30\n",
      "77/77 [==============================] - 219s 3s/step - loss: 1.7381\n",
      "Epoch 8/30\n",
      "77/77 [==============================] - 248s 3s/step - loss: 1.6642\n",
      "Epoch 9/30\n",
      "77/77 [==============================] - 266s 3s/step - loss: 1.6124\n",
      "Epoch 10/30\n",
      "77/77 [==============================] - 265s 3s/step - loss: 1.5648\n",
      "Epoch 11/30\n",
      "77/77 [==============================] - 270s 3s/step - loss: 1.5294\n",
      "Epoch 12/30\n",
      "77/77 [==============================] - 270s 3s/step - loss: 1.4971\n",
      "Epoch 13/30\n",
      "77/77 [==============================] - 255s 3s/step - loss: 1.4640\n",
      "Epoch 14/30\n",
      "77/77 [==============================] - 260s 3s/step - loss: 1.4406\n",
      "Epoch 15/30\n",
      "77/77 [==============================] - 260s 3s/step - loss: 1.4153\n",
      "Epoch 16/30\n",
      "77/77 [==============================] - 268s 3s/step - loss: 1.3936\n",
      "Epoch 17/30\n",
      "77/77 [==============================] - 266s 3s/step - loss: 1.3749\n",
      "Epoch 18/30\n",
      "77/77 [==============================] - 265s 3s/step - loss: 1.3575\n",
      "Epoch 19/30\n",
      "77/77 [==============================] - 267s 3s/step - loss: 1.3418\n",
      "Epoch 20/30\n",
      "77/77 [==============================] - 259s 3s/step - loss: 1.3255\n",
      "Epoch 21/30\n",
      "77/77 [==============================] - 264s 3s/step - loss: 1.3077\n",
      "Epoch 22/30\n",
      "77/77 [==============================] - 252s 3s/step - loss: 1.2957\n",
      "Epoch 23/30\n",
      "77/77 [==============================] - 258s 3s/step - loss: 1.2782\n",
      "Epoch 24/30\n",
      "77/77 [==============================] - 245s 3s/step - loss: 1.2684\n",
      "Epoch 25/30\n",
      "77/77 [==============================] - 255s 3s/step - loss: 1.2530\n",
      "Epoch 26/30\n",
      "77/77 [==============================] - 248s 3s/step - loss: 1.2391\n",
      "Epoch 27/30\n",
      "77/77 [==============================] - 240s 3s/step - loss: 1.2267\n",
      "Epoch 28/30\n",
      "77/77 [==============================] - 241s 3s/step - loss: 1.2135\n",
      "Epoch 29/30\n",
      "77/77 [==============================] - 257s 3s/step - loss: 1.1995\n",
      "Epoch 30/30\n",
      "77/77 [==============================] - 256s 3s/step - loss: 1.1908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec30668ba8>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset,epochs=30) # you must use GPU version of tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "vgbCK5FW8fK2"
   },
   "outputs": [],
   "source": [
    "model.save('moby_dick.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "moby.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
